{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/JuliethLopez/dlaicoursePractica/blob/master/3.Computer%20vision%20with%20convolutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Cladificacion deep learning__\n",
    "\n",
    "TEST\n",
    "\n",
    "313/313 [==============================] - 1s 2ms/step - loss: 0.3566 - accuracy: 0.8727\n",
    "\n",
    "__ClasificaciÃ³n convolution__ *better*\n",
    "\n",
    "TEST\n",
    "\n",
    "313/313 [==============================] - 1s 2ms/step - loss: 0.2823 - accuracy: 0.8988"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First convolution expects a single tensor containing everything, so instead of 60,000 28x28x1 items in a list, we have a single 4D list that is 60,000x28x28x1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images=training_images.reshape(60000, 28, 28, 1)\n",
    "training_images=training_images / 255.0\n",
    "test_images = test_images.reshape(10000, 28, 28, 1)\n",
    "test_images=test_images/255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(training_images, training_labels, epochs=10)\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see what is happening in each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "f, axarr = plt.subplots(3,4)\n",
    "FIRST_IMAGE=6#0\n",
    "SECOND_IMAGE=7#7\n",
    "THIRD_IMAGE=26#26\n",
    "CONVOLUTION_NUMBER = 1\n",
    "from tensorflow.keras import models\n",
    "layer_outputs = [layer.output for layer in model.layers]\n",
    "activation_model = tf.keras.models.Model(inputs = model.input, outputs = layer_outputs)\n",
    "for x in range(0,4):\n",
    "  f1 = activation_model.predict(test_images[FIRST_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "  axarr[0,x].imshow(f1[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "  axarr[0,x].grid(False)\n",
    "  f2 = activation_model.predict(test_images[SECOND_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "  axarr[1,x].imshow(f2[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "  axarr[1,x].grid(False)\n",
    "  f3 = activation_model.predict(test_images[THIRD_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "  axarr[2,x].imshow(f3[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "  axarr[2,x].grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this comparations we are using 10 epochs, and we are taking the test accuracy\n",
    "1. Test accuracy\n",
    "    - convolution 64 (0.9869)\n",
    "    - convolution 32 (0.9867)\n",
    "    - convolution 16 (0.9833)\n",
    "2. Test accuracy\n",
    "    - 2 convolutions 64 (0.9899)\n",
    "    - 1 convolution 64 (0.9869)\n",
    "3. Test accuracy\n",
    "    - 3 convolutions 64 (0.9862)\n",
    "4. Test accuracy\n",
    "    - with convolution 64 (0.9869)\n",
    "    - without convolution (0.9790)\n",
    "    \n",
    "Now we'll put a callback function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "def train_mnist():\n",
    "\n",
    "    class myCallback(tf.keras.callbacks.Callback):\n",
    "      def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy')>0.98):\n",
    "          print(\"\\nReached 98% accuracy so cancelling training!\")\n",
    "          self.model.stop_training = True\n",
    "\n",
    "    callbacks = myCallback()\n",
    "\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "    (training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "    training_images=training_images.reshape(60000, 28, 28, 1)\n",
    "    training_images=training_images / 255.0\n",
    "    test_images = test_images.reshape(10000, 28, 28, 1)\n",
    "    test_images=test_images/255.0\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "      tf.keras.layers.MaxPooling2D(2, 2),\n",
    "      tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "      tf.keras.layers.MaxPooling2D(2, 2),\n",
    "      tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "      tf.keras.layers.MaxPooling2D(2, 2),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(128, activation='relu'),\n",
    "      tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(training_images, training_labels, epochs=10, callbacks=[callbacks])\n",
    "    test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "\n",
    "    return history.epoch, history.history['accuracy'][-1], test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few rules about the filter:\n",
    "- Its size has to be uneven, so that it has a center, for example 3x3, 5x5 and 7x7 are ok.\n",
    "- It doesn't have to, but the sum of all elements of the filter should be 1 if you want the resulting image to have the same brightness as the original.\n",
    "- If the sum of the elements is larger than 1, the result will be a brighter image, and if it's smaller than 1, a darker image. If the sum is 0, the resulting image isn't necessarily completely black, but it'll be very dark.\n",
    "\n",
    "[How is a hand made convolution?](https://github.com/lmoroney/dlaicourse/blob/master/Course%201%20-%20Part%206%20-%20Lesson%203%20-%20Notebook.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
